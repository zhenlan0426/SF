{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import createDataMain,createTestDataMain,pd2np\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "discreteList = ['dayOfWeek','payDay','month','earthquake',\\\n",
    "                'type','locale','locale_name','transferred','onpromotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"dateVar.pickle\", \"rb\") as input_file:\n",
    "    dateVar_list = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "types = {'id': 'int32',\n",
    "     'item_nbr': 'int32',\n",
    "     'store_nbr': 'int8',\n",
    "     'unit_sales': 'float32',\n",
    "     'onpromotion': bool}\n",
    "train = pd.read_csv('train.csv',usecols=['date','item_nbr','store_nbr','unit_sales','onpromotion'],\\\n",
    "                    parse_dates=['date'],dtype=types, infer_datetime_format=True)\n",
    "train = train.fillna(2,axis=1)\n",
    "train.onpromotion = train.onpromotion.astype(np.int8)\n",
    "train.loc[train.unit_sales<0,'unit_sales'] = .0 # clip negative sales to zero\n",
    "item_uniq = pd.unique(train.item_nbr)\n",
    "item_dict = {item:i+1 for i,item in enumerate(item_uniq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"item_dict_train.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(item_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.date < '2017-07-31']\n",
    "item_uniq = pd.unique(train.item_nbr)\n",
    "item_dict = {item:i+1 for i,item in enumerate(item_uniq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"item_dict_final.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(item_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "train,val = createDataMain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_np, weight_np,Con_np,Dis_np,X_np,Count_np = \\\n",
    "            pd2np(val,batch_size,val.countDays.max(),dateVar_list,'date',discreteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(prefix+'_Y',y_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Weight',weight_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Con',Con_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_X',X_np,fmt=\"%d\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Count',Count_np,fmt=\"%d\",delimiter=\",\") \n",
    "for j in range(len(discreteList)):\n",
    "    np.savetxt(prefix+'_Dis'+str(j),Dis_np[:,:,j],fmt=\"%d\",delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_np, weight_np,Con_np,Dis_np,X_np,Count_np = \\\n",
    "            pd2np(train,batch_size,train.countDays.max(),dateVar_list,'date',discreteList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(prefix+'_Y',y_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Weight',weight_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Con',Con_np,fmt=\"%f\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_X',X_np,fmt=\"%d\",delimiter=\",\") \n",
    "np.savetxt(prefix+'_Count',Count_np,fmt=\"%d\",delimiter=\",\") \n",
    "for j in range(len(discreteList)):\n",
    "    np.savetxt(prefix+'_Dis'+str(j),Dis_np[:,:,j],fmt=\"%d\",delimiter=\",\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = np.loadtxt(prefix+'_Y',dtype=np.float32, delimiter=\",\") \n",
    "weight_np = np.loadtxt(prefix+'_Weight',dtype=np.float32, delimiter=\",\") \n",
    "Con_np = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Count_np = np.loadtxt(prefix+'_Count',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174140, 1672)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dis_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Save2Disk(data,batchSize,seqSize,df,key,discreteList,prefix):\n",
    "    n = data.shape[0]\n",
    "    d = len(discreteList)\n",
    "    Y,Con = file(prefix+'_Y.csv','a'),file(prefix+'_Con.csv','a')\n",
    "    Dis = [file(prefix+'_Dis'+str(i)+'.csv','a') for i in range(d)]\n",
    "    for y,con,dis in RNN_generator2(data,batchSize,seqSize,df,key,discreteList):\n",
    "        np.savetxt(Y,y,fmt=\"%f\",delimiter=\",\")  \n",
    "        np.savetxt(Con,con,fmt=\"%f\",delimiter=\",\")  \n",
    "        for j,Dis_j in enumerate(Dis):\n",
    "            np.savetxt(Dis_j,dis[:,:,j],fmt=\"%d\",delimiter=\",\")  \n",
    "    \n",
    "    Y.close()    \n",
    "    Con.close()\n",
    "    for Dis_j in Dis:\n",
    "        Dis_j.close()\n",
    "    weight = np.ones((n,1),dtype=np.float32)\n",
    "    weight[data['perishable']==1] = 1.25\n",
    "    np.savetxt(prefix+'_Weight.csv', weight, delimiter=',')\n",
    "    np.savetxt(prefix+'_Count.csv', fmt=\"%d\",data['countDays'].values.astype(np.int32), delimiter=',')\n",
    "\n",
    "\n",
    "def RNN_generator2(data,batchSize,seqSize,df,key,discreteList):\n",
    "    n = data.shape[0]\n",
    "    for from_ in range(0,n,batchSize):\n",
    "        for y,Xdiscrete,Xcontinue in timeGenerator2(data.loc[from_:from_+batchSize-1,'date':'amax'],\\\n",
    "                                                      seqSize,df,key,discreteList):\n",
    "            yield y,Xcontinue, Xdiscrete\n",
    "            \n",
    "def timeGenerator2(data,seqSize,df,key,discreteList):\n",
    "    # df is time related variables like holiday and seasonality\n",
    "    # returns y, X_discrete, X_continue\n",
    "    n = data.shape[0]\n",
    "    sparse = pd.concat([data.apply(lambda x: pd.Series(x.date,name='date'),axis=1)\\\n",
    "                                    .stack().reset_index().drop(['level_1'],1),\\\n",
    "                        data.apply(lambda x: pd.Series(x.unit_sales),axis=1)\\\n",
    "                                    .stack().reset_index().drop(['level_0','level_1'],1),\\\n",
    "                        data.apply(lambda x: pd.Series(x.onpromotion),axis=1)\\\n",
    "                                    .stack().reset_index().drop(['level_0','level_1'],1)],1)\n",
    "    sparse.columns = ['level','date','sales','onpromotion']\n",
    "\n",
    "    dense = data.apply(lambda x:pd.Series(pd.date_range(x.amin,periods=seqSize)),axis=1)\\\n",
    "                        .stack().reset_index().drop(['level_1'],1)\n",
    "    dense.columns = ['level','date']\n",
    "    dense = pd.merge(pd.merge(dense, df[np.random.randint(10)], how='left', on=key),\n",
    "                    sparse,how='left',on=['level','date']).fillna(0)\n",
    "    dense_continue = dense['dcoilwtico'].values.astype(np.float32).reshape((n,seqSize))\n",
    "    dense_discrete = dense[discreteList].values.astype(np.int32)\\\n",
    "                        .reshape((n,seqSize,len(discreteList)))\n",
    "    y = dense['sales'].values.astype(np.float32).reshape((n,seqSize))\n",
    "\n",
    "    yield y, dense_discrete, dense_continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
