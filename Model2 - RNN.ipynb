{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from functions import RNN_generator,createGraphRNN,init_state_update,RNN_forecast\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discreteList = ['dayOfWeek','payDay','month','earthquake','type','locale','locale_name','transferred','onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_len = 16 # same as test set for convenience\n",
    "learningRate = 1e-4\n",
    "epoch = 30\n",
    "keep_prob = 0.75\n",
    "n_layers = 2\n",
    "grad_clip = 5.0\n",
    "bucketSize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinalitys_X = [55, 4001, 34, 337, 2, 23, 17, 6, 18]\n",
    "cardinalitys_T = [7, 2, 13, 2, 7, 4, 25, 2, 3]\n",
    "dimentions_X = [2, 20, 1, 2, 1, 1, 1, 1, 1]\n",
    "dimentions_T = [1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dX = sum(dimentions_X)\n",
    "dT = sum(dimentions_T)\n",
    "d = dX + dT + 2 # 2 for two cont variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Build Computation Graph ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs,train_op,cost,saver,yhat,state = createGraphRNN(batch_size,seq_len,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monitor = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'train'\n",
    "y_np = np.loadtxt(prefix+'_Y',dtype=np.float32, delimiter=\",\") \n",
    "weight_np = np.loadtxt(prefix+'_Weight',dtype=np.float32, delimiter=\",\") \n",
    "Con_np = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Count_np = np.loadtxt(prefix+'_Count',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:1.0707811526\n",
      "Train loss:1.17701104471\n",
      "Train loss:0.737318389879\n",
      "Train loss:0.945108429562\n",
      "Train loss:0.692611600789\n",
      "Train loss:0.659711074998\n",
      "Train loss:0.680858915046\n",
      "Train loss:0.767058903531\n",
      "Train loss:0.567084150898\n",
      "Train loss:0.854408263656\n",
      "Train loss:0.901076634781\n",
      "Train loss:0.587735888105\n",
      "Train loss:0.75338859048\n",
      "Train loss:1.02932318112\n",
      "Train loss:0.741012220243\n",
      "Train loss:0.97104880124\n",
      "Train loss:0.725687093183\n",
      "Train loss:0.620021128458\n",
      "Train loss:0.622400138615\n",
      "Train loss:0.616401926904\n",
      "Train loss:0.62834886836\n",
      "Train loss:0.637478776508\n",
      "Train loss:0.617297901051\n",
      "Train loss:0.527405754224\n",
      "Train loss:0.527930968799\n",
      "Train loss:0.519474792752\n",
      "Train loss:0.58348647088\n",
      "Train loss:0.568743405619\n",
      "Train loss:0.734537856134\n",
      "Train loss:0.792956502281\n"
     ]
    }
   ],
   "source": [
    "init_state = tuple([np.zeros((batch_size,d),dtype=np.float32) for i in range(n_layers)])\n",
    "for i in range(epoch):\n",
    "    cost_train = .0\n",
    "    weight_train = .0\n",
    "    #cost_val = .0\n",
    "    #weight_val = .0\n",
    "    for j,X_nps in enumerate(RNN_generator(y_np, weight_np,Con_np,Dis_np,X_np,Count_np,\\\n",
    "                              batch_size,seq_len,bucketSize,downSample=0.9)):\n",
    "        _,cost_np,init_state = sess.run([train_op,cost,state],\\\n",
    "                             dict(zip(inputs,X_nps+[learningRate,init_state])))\n",
    "        cost_train += cost_np\n",
    "        weight_train = weight_train + np.sum(X_nps[1])\n",
    "        \n",
    "        if j%monitor == 0:\n",
    "        \n",
    "            print \"Train loss:{}\".format(np.sqrt(seq_len*batch_size*cost_train/weight_train))\n",
    "            cost_train = .0\n",
    "            weight_train = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNN_fillin_01'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model parameters\n",
    "saver.save(sess,'RNN_fillin_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*** Prediction ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs,train_op,cost,saver,yhat,state = createGraphRNN(None,1,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess,'RNN_fillin_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.loadtxt('Index',dtype=np.int32,delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_tot_list = init_state_update(sess,inputs,state,batch_size*10,d,n_layers,\\\n",
    "                                  y_np[index],Con_np[index],X_np[index],Count_np[index],\\\n",
    "                                  [dis[index] for dis in Dis_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'test_SI'\n",
    "y_np_SI = np.loadtxt(prefix+'_Y',dtype=np.int32, delimiter=\",\") \n",
    "Con_np_SI = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np_SI = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np_SI = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SI = RNN_forecast(sess,inputs,state,yhat,batch_size*10,n_layers,\\\n",
    "                     np.expand_dims(y_np[index,Count_np[index]-1],-1)\\\n",
    "                    ,Con_np_SI,X_np_SI,Dis_np_SI,init_tot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
