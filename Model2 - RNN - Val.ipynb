{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from functions import RNN_generator,createGraphRNN,init_state_update,RNN_forecast_Repeat,loss_func\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discreteList = ['dayOfWeek','payDay','month','earthquake','type','locale','locale_name','transferred','onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_len = 16 # same as test set for convenience\n",
    "learningRate = 1e-4\n",
    "epoch = 30\n",
    "keep_prob = 0.75\n",
    "n_layers = 2\n",
    "grad_clip = 5.0\n",
    "bucketSize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinalitys_X = [55, 4001, 34, 337, 2, 23, 17, 6, 18]\n",
    "cardinalitys_T = [7, 2, 13, 2, 7, 4, 25, 2, 3]\n",
    "dimentions_X = [2, 20, 1, 2, 1, 1, 1, 1, 1]\n",
    "dimentions_T = [1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dX = sum(dimentions_X)\n",
    "dT = sum(dimentions_T)\n",
    "d = dX + dT + 2 # 2 for two cont variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Build Computation Graph ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs,train_op,cost,saver,yhat,state = createGraphRNN(batch_size,seq_len,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monitor = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'train'\n",
    "y_np = np.loadtxt(prefix+'_Y',dtype=np.float32, delimiter=\",\") \n",
    "weight_np = np.loadtxt(prefix+'_Weight',dtype=np.float32, delimiter=\",\") \n",
    "Con_np = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Count_np = np.loadtxt(prefix+'_Count',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'val_SI'\n",
    "y_np_val = np.loadtxt(prefix+'_Y',dtype=np.float32, delimiter=\",\") \n",
    "weight_np_val = np.loadtxt(prefix+'_Weight',dtype=np.float32, delimiter=\",\") \n",
    "Con_np_val = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np_val = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Count_np_val = np.loadtxt(prefix+'_Count',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np_val = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.loadtxt('Index_val',dtype=np.int32,delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:1.08884670045,Val Loss:5.6944861412\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:1.09453279027,Val Loss:4.60185289383\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.856183945778,Val Loss:4.33840370178\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.932031309756,Val Loss:4.22241544724\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.777827130165,Val Loss:4.13084363937\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:1.0011212277,Val Loss:4.05689525604\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.729772225406,Val Loss:3.9708943367\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.888870857116,Val Loss:3.90755629539\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.903255015142,Val Loss:3.82835030556\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.810612450691,Val Loss:3.7710211277\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.760544811091,Val Loss:3.72281694412\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.83738250247,Val Loss:3.68067789078\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.694590751226,Val Loss:3.63420367241\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.731475122323,Val Loss:3.60165953636\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.863826130433,Val Loss:3.56680321693\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.636057989135,Val Loss:3.53731179237\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.668444230411,Val Loss:3.51465892792\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.743896498838,Val Loss:3.49645256996\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.707495614972,Val Loss:3.48001813889\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.59881290369,Val Loss:3.46737766266\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.58440351191,Val Loss:3.45484399796\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.64333476685,Val Loss:3.44277763367\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.74640081049,Val Loss:3.43278408051\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.583915619933,Val Loss:3.42323756218\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.670769757645,Val Loss:3.41484475136\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.563200367733,Val Loss:3.40982460976\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.689438921653,Val Loss:3.40319442749\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.616258534987,Val Loss:3.39618873596\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.519774750863,Val Loss:3.39198064804\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n",
      "Train loss:0.884051733527,Val Loss:3.38684034348\n",
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n"
     ]
    }
   ],
   "source": [
    "init_state = tuple([np.zeros((batch_size,d),dtype=np.float32) for i in range(n_layers)])\n",
    "for i in range(epoch):\n",
    "    cost_train = .0\n",
    "    weight_train = .0\n",
    "    for j,X_nps in enumerate(RNN_generator(y_np, weight_np,Con_np,Dis_np,X_np,Count_np,\\\n",
    "                              batch_size,seq_len,bucketSize,downSample=0.9)):\n",
    "        _,cost_np,init_state = sess.run([train_op,cost,state],\\\n",
    "                             dict(zip(inputs,X_nps+[learningRate,init_state])))\n",
    "        cost_train += cost_np\n",
    "        weight_train = weight_train + np.sum(X_nps[1])\n",
    "        \n",
    "        if j%monitor == 0:\n",
    "            saver.save(sess,'RNN_fillin_01')\n",
    "            inputs,train_op,cost,saver,yhat,state = createGraphRNN(None,1,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)\n",
    "            sess = tf.InteractiveSession()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess,'RNN_fillin_01')\n",
    "            init_tot_list = init_state_update(sess,inputs,state,batch_size*10,d,n_layers,\\\n",
    "                                  y_np[index],Con_np[index],X_np[index],Count_np[index],\\\n",
    "                                  [dis[index] for dis in Dis_np])\n",
    "            y_val_hat = RNN_forecast_Repeat(10,sess,inputs,state,yhat,batch_size*10,n_layers,\\\n",
    "                                            np.expand_dims(y_np[index,Count_np[index]-1],-1),\\\n",
    "                                            Con_np_val,X_np_val,Dis_np_val,init_tot_list)\n",
    "            print \"Train loss:{},Val Loss:{}\".format(np.sqrt(seq_len*batch_size*cost_train/weight_train),\\\n",
    "                                                    loss_func(weight_np_val[:,np.newaxis],y_val_hat,y_np_val))\n",
    "            cost_train = .0\n",
    "            weight_train = .0\n",
    "            inputs,train_op,cost,saver,yhat,state = createGraphRNN(batch_size,seq_len,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)\n",
    "            sess = tf.InteractiveSession()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess,'RNN_fillin_01')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
