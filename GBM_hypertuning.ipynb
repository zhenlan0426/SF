{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hyperopt import hp, fmin, tpe\n",
    "from functions import CreatDataGBM\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2821: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_val,Y_val,Weight = CreatDataGBM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE_exp(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = np.exp(preds)\n",
    "    temp1 = preds/(preds+1)\n",
    "    temp2 = np.log(preds+1) - labels\n",
    "    return temp2*temp1, temp1*temp1 + temp2*temp1*(1-temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE_relu(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds2 = np.maximum(preds,0)\n",
    "    inc = preds>0\n",
    "    temp1 = inc/(1+preds2)\n",
    "    temp2 = np.log(preds2+1) - labels\n",
    "    sq = temp1*temp1\n",
    "    return temp2*temp1, sq - temp2*sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def NWRMSLE_sq(preds, dtrain):\\n    labels = dtrain.get_label()\\n    preds2 = preds**2\\n    temp1 = preds/(1+preds2)\\n    temp2 = np.log(preds2+1) - labels\\n    return temp2*temp1, temp1*temp1 + temp2*(3*preds2+1)/(preds2+1)**2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def NWRMSLE_sq(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds2 = preds**2\n",
    "    temp1 = preds/(1+preds2)\n",
    "    temp2 = np.log(preds2+1) - labels\n",
    "    return temp2*temp1, temp1*temp1 + temp2*(3*preds2+1)/(preds2+1)**2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objective_fun = [(NWRMSLE_exp,np.exp),(NWRMSLE_relu,lambda x:np.maximum(x,0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(Weight,yhat,y):\n",
    "    return np.sqrt(np.sum(Weight*(np.log(yhat+1)-y)**2)/np.sum(Weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['eta'] = 0.25\n",
    "param['max_depth'] = 10\n",
    "param['min_child_weight'] = 1\n",
    "param['tree_method'] = 'hist'\n",
    "monitor = 20\n",
    "monitorTimes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperSearchGBM(paras):   \n",
    "    model_para = param.copy()\n",
    "    model_para['subsample'] = paras[0]\n",
    "    model_para['colsample_bytree'] = paras[1]\n",
    "    model_para['gamma'] = paras[2]\n",
    "    obj,link = objective_fun[paras[3]]\n",
    "    tot_loss = 0\n",
    "    for i in range(16):\n",
    "        dtrain = xgb.DMatrix(\n",
    "            X_train, label=Y_train[:, i],\n",
    "            weight=np.tile(Weight,16)\n",
    "        )\n",
    "        dval = xgb.DMatrix(\n",
    "            X_val, label=Y_val[:, i],\n",
    "            weight=Weight)\n",
    "        \n",
    "        best_loss = 100\n",
    "        for j in range(monitorTimes):           \n",
    "            # train\n",
    "            if j == 0:\n",
    "                model = xgb.train(model_para, dtrain, monitor,obj=obj)\n",
    "            else:\n",
    "                model = xgb.train(model_para, dtrain, monitor,obj=NWRMSLE_relu,xgb_model=model)\n",
    "            # eval\n",
    "            yhat = link(model.predict(dval,output_margin=True))\n",
    "            loss = loss_func(Weight,yhat,Y_val[:, i])\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "            else:\n",
    "                break # early stop\n",
    "        tot_loss = tot_loss + best_loss\n",
    "\n",
    "    tot_loss = tot_loss/16    \n",
    "    print \"loss:{} , subsample:{}, colsample:{}, gamma:{} ,objective:{} \\n\"\\\n",
    "              .format(tot_loss,paras[0],paras[1],paras[2],paras[3])  \n",
    "    return tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space = [hp.uniform('subsample',0.01,0.15),\\\n",
    "         hp.uniform('colsample',0.1,0.8),\\\n",
    "         hp.uniform('gamma',1,100),\\\n",
    "         hp.choice('models',[0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.449536966995 , subsample:0.0550761473573, colsample:0.645103497042, gamma:51.3732251887 ,objective:0 \n",
      "\n",
      "loss:0.451796226477 , subsample:0.138429686425, colsample:0.501925709187, gamma:1.9867476064 ,objective:0 \n",
      "\n",
      "loss:0.431957986459 , subsample:0.0556206950421, colsample:0.526688633213, gamma:10.3156374802 ,objective:1 \n",
      "\n",
      "loss:0.473952657583 , subsample:0.0416467203721, colsample:0.394301144392, gamma:50.3403500953 ,objective:0 \n",
      "\n",
      "loss:0.4412054121 , subsample:0.139355950746, colsample:0.172517980542, gamma:23.0057283308 ,objective:1 \n",
      "\n",
      "loss:0.440183298222 , subsample:0.0945076372895, colsample:0.291004901366, gamma:72.744758734 ,objective:1 \n",
      "\n",
      "loss:0.43047335466 , subsample:0.0721617898053, colsample:0.766616468485, gamma:28.7265834674 ,objective:1 \n",
      "\n",
      "loss:0.463586819607 , subsample:0.110491032977, colsample:0.329793243217, gamma:29.0351299682 ,objective:0 \n",
      "\n",
      "loss:0.459741106811 , subsample:0.0430870172236, colsample:0.534802592304, gamma:29.0052059014 ,objective:0 \n",
      "\n",
      "loss:0.452176726444 , subsample:0.102837679319, colsample:0.584691109305, gamma:77.8473727415 ,objective:0 \n",
      "\n",
      "loss:0.48904861078 , subsample:0.0943287011393, colsample:0.289421180016, gamma:62.0967617553 ,objective:0 \n",
      "\n",
      "loss:0.463798302245 , subsample:0.127729144063, colsample:0.125996862964, gamma:91.6726432543 ,objective:1 \n",
      "\n",
      "loss:0.43342342081 , subsample:0.113166897362, colsample:0.675225804067, gamma:77.3638086326 ,objective:1 \n",
      "\n",
      "loss:0.45859736875 , subsample:0.102624390471, colsample:0.428494686388, gamma:70.692258453 ,objective:0 \n",
      "\n",
      "loss:0.455309752349 , subsample:0.0382806680616, colsample:0.589546061057, gamma:41.9114253648 ,objective:0 \n",
      "\n",
      "loss:0.439342097366 , subsample:0.14118871714, colsample:0.243678259454, gamma:52.5763303697 ,objective:1 \n",
      "\n",
      "loss:0.457381825041 , subsample:0.114387171636, colsample:0.493761762722, gamma:82.8604937834 ,objective:0 \n",
      "\n",
      "loss:0.454336531632 , subsample:0.12792996418, colsample:0.130327833651, gamma:41.8849589247 ,objective:1 \n",
      "\n",
      "loss:0.476112297185 , subsample:0.012608418563, colsample:0.47353287307, gamma:65.0076992536 ,objective:0 \n",
      "\n",
      "loss:0.428748532779 , subsample:0.141183024362, colsample:0.799520809273, gamma:55.0131302522 ,objective:1 \n",
      "\n",
      "loss:0.428547794793 , subsample:0.074976639842, colsample:0.799778171756, gamma:16.9421261368 ,objective:1 \n",
      "\n",
      "loss:0.42749003189 , subsample:0.0772514936229, colsample:0.784514959714, gamma:16.1161847747 ,objective:1 \n",
      "\n",
      "loss:0.428437711124 , subsample:0.0798351485908, colsample:0.751667975835, gamma:13.0134150712 ,objective:1 \n",
      "\n",
      "loss:0.425311280454 , subsample:0.0645388087658, colsample:0.747962181579, gamma:2.47947835961 ,objective:1 \n",
      "\n",
      "loss:0.434471071332 , subsample:0.0256043764378, colsample:0.702149094117, gamma:1.71516240774 ,objective:1 \n",
      "\n",
      "loss:0.425421920127 , subsample:0.0629887897836, colsample:0.729299373267, gamma:4.27391753974 ,objective:1 \n",
      "\n",
      "loss:0.425654984053 , subsample:0.0641640644514, colsample:0.714154606234, gamma:1.29025071469 ,objective:1 \n",
      "\n",
      "loss:0.445044671112 , subsample:0.0265749577667, colsample:0.620309436693, gamma:35.673344453 ,objective:1 \n",
      "\n",
      "loss:0.428618337315 , subsample:0.0578358916952, colsample:0.648727144918, gamma:8.03651316227 ,objective:1 \n",
      "\n",
      "loss:0.428539405247 , subsample:0.0882564485055, colsample:0.725508619809, gamma:21.0008219105 ,objective:1 \n",
      "\n",
      "loss:0.429928700628 , subsample:0.0498350844165, colsample:0.583819996501, gamma:7.01239041472 ,objective:1 \n",
      "\n",
      "loss:0.42728177316 , subsample:0.0646359148418, colsample:0.660917860561, gamma:7.12440441383 ,objective:1 \n",
      "\n",
      "loss:0.461480884878 , subsample:0.0104297948651, colsample:0.548410568811, gamma:39.2453632127 ,objective:1 \n",
      "\n",
      "loss:0.444663541026 , subsample:0.0263567262243, colsample:0.395956205457, gamma:23.317604902 ,objective:1 \n",
      "\n",
      "loss:0.42361359868 , subsample:0.0867126519427, colsample:0.620913624925, gamma:1.85324297071 ,objective:1 \n",
      "\n",
      "loss:0.431909930842 , subsample:0.087993599111, colsample:0.627544838009, gamma:34.4130313388 ,objective:1 \n",
      "\n",
      "loss:0.438161684235 , subsample:0.0509031038902, colsample:0.678446889632, gamma:47.9406064274 ,objective:1 \n",
      "\n",
      "loss:0.439987677917 , subsample:0.0708292908055, colsample:0.519415041172, gamma:94.1751730395 ,objective:1 \n",
      "\n",
      "loss:0.42944590396 , subsample:0.0852183868423, colsample:0.43835553224, gamma:12.5795040274 ,objective:1 \n",
      "\n",
      "loss:0.4273166108 , subsample:0.12295478296, colsample:0.55972715275, gamma:25.2494104429 ,objective:1 \n",
      "\n",
      "loss:0.443517843989 , subsample:0.148581150805, colsample:0.610269819856, gamma:15.9993766494 ,objective:0 \n",
      "\n",
      "loss:0.436862245452 , subsample:0.0987450793925, colsample:0.355795717174, gamma:58.7448649389 ,objective:1 \n",
      "\n",
      "loss:0.451145244548 , subsample:0.0372536911017, colsample:0.464505624903, gamma:88.0452797787 ,objective:1 \n",
      "\n",
      "loss:0.437340102912 , subsample:0.109015800223, colsample:0.746960951839, gamma:30.9378260148 ,objective:0 \n",
      "\n",
      "loss:0.433484405034 , subsample:0.0694581854306, colsample:0.770562576924, gamma:47.9137737371 ,objective:1 \n",
      "\n",
      "loss:0.44892906511 , subsample:0.0484796124297, colsample:0.694470358072, gamma:19.7164839887 ,objective:0 \n",
      "\n",
      "loss:0.424610972947 , subsample:0.0945980990125, colsample:0.403359443513, gamma:1.8212060034 ,objective:1 \n",
      "\n",
      "loss:0.4423780655 , subsample:0.120529271262, colsample:0.277691556263, gamma:69.0869485021 ,objective:1 \n",
      "\n",
      "loss:0.520287482851 , subsample:0.134117932317, colsample:0.207502828628, gamma:99.6020038246 ,objective:0 \n",
      "\n",
      "loss:0.431829289889 , subsample:0.105733970085, colsample:0.352760245752, gamma:25.6128806816 ,objective:1 \n",
      "\n",
      "loss:0.459696431968 , subsample:0.0962066174899, colsample:0.403186196037, gamma:10.5437353352 ,objective:0 \n",
      "\n",
      "loss:0.437329694779 , subsample:0.0915575452401, colsample:0.321036259928, gamma:32.1757451625 ,objective:1 \n",
      "\n",
      "loss:0.434723434639 , subsample:0.0826287669264, colsample:0.499914613549, gamma:43.0516243177 ,objective:1 \n",
      "\n",
      "loss:0.448987794884 , subsample:0.101848715198, colsample:0.166600031143, gamma:27.1271820167 ,objective:1 \n",
      "\n",
      "loss:0.499162454309 , subsample:0.116163869662, colsample:0.259290265777, gamma:76.4220684171 ,objective:0 \n",
      "\n",
      "loss:0.428091179185 , subsample:0.129915595629, colsample:0.413727373286, gamma:19.0730412717 ,objective:1 \n",
      "\n",
      "loss:0.422801549007 , subsample:0.119398299563, colsample:0.367823795823, gamma:4.43745570732 ,objective:1 \n",
      "\n",
      "loss:0.507222753253 , subsample:0.116947204033, colsample:0.216415697061, gamma:38.2549929465 ,objective:0 \n",
      "\n",
      "loss:0.426283050743 , subsample:0.149967898737, colsample:0.317512929094, gamma:12.7330129058 ,objective:1 \n",
      "\n",
      "loss:0.42278735049 , subsample:0.133448450345, colsample:0.367127373623, gamma:5.18910389561 ,objective:1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best = fmin(hyperSearchGBM,space,tpe.suggest,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine number of iterations for smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['eta'] = 0.05\n",
    "param['max_depth'] = 10\n",
    "param['min_child_weight'] = 1\n",
    "param['tree_method'] = 'hist'\n",
    "monitor = 100\n",
    "monitorTimes = 10\n",
    "best_numberStep_list = []\n",
    "Y_ensemble = np.zeros((yhat.shape[0],16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:0, iteration:100, loss:0.448519396937\n",
      "model:0, iteration:200, loss:0.409481455129\n",
      "model:0, iteration:300, loss:0.404412220765\n",
      "model:0, iteration:400, loss:0.403457361237\n",
      "model:0, iteration:500, loss:0.403002472531\n",
      "model:0, iteration:600, loss:0.402613365348\n",
      "model:0, iteration:700, loss:0.402369634941\n",
      "model:0, iteration:800, loss:0.402210586201\n",
      "model:0, iteration:900, loss:0.401973402677\n",
      "model:0, iteration:1000, loss:0.401864974931\n",
      "model:1, iteration:100, loss:0.507223579626\n",
      "model:1, iteration:200, loss:0.447702234991\n",
      "model:1, iteration:300, loss:0.440161349527\n",
      "model:1, iteration:400, loss:0.437287669192\n",
      "model:1, iteration:500, loss:0.436030312213\n",
      "model:1, iteration:600, loss:0.435662906922\n",
      "model:1, iteration:700, loss:0.435279301057\n",
      "model:1, iteration:800, loss:0.43503370697\n",
      "model:1, iteration:900, loss:0.434904704589\n",
      "model:1, iteration:1000, loss:0.434914598316\n",
      "model:2, iteration:100, loss:0.481579413111\n",
      "model:2, iteration:200, loss:0.429252650796\n",
      "model:2, iteration:300, loss:0.422461186281\n",
      "model:2, iteration:400, loss:0.421450362519\n",
      "model:2, iteration:500, loss:0.42120549802\n",
      "model:2, iteration:600, loss:0.42127516334\n",
      "model:3, iteration:100, loss:0.428511625189\n",
      "model:3, iteration:200, loss:0.417062048779\n",
      "model:3, iteration:300, loss:0.418466225094\n",
      "model:4, iteration:100, loss:0.450387211219\n",
      "model:4, iteration:200, loss:0.434229301285\n",
      "model:4, iteration:300, loss:0.435128096981\n",
      "model:5, iteration:100, loss:0.462155154464\n",
      "model:5, iteration:200, loss:0.423416302217\n",
      "model:5, iteration:300, loss:0.420855388021\n",
      "model:5, iteration:400, loss:0.420309637904\n",
      "model:5, iteration:500, loss:0.420161125172\n",
      "model:5, iteration:600, loss:0.420361109917\n",
      "model:6, iteration:100, loss:0.494331232754\n",
      "model:6, iteration:200, loss:0.437614017574\n",
      "model:6, iteration:300, loss:0.431870116132\n",
      "model:6, iteration:400, loss:0.430383891146\n",
      "model:6, iteration:500, loss:0.42986658853\n",
      "model:6, iteration:600, loss:0.429469236548\n",
      "model:6, iteration:700, loss:0.429132158852\n",
      "model:6, iteration:800, loss:0.429007783508\n",
      "model:6, iteration:900, loss:0.428604890698\n",
      "model:6, iteration:1000, loss:0.428430376271\n",
      "model:7, iteration:100, loss:0.445340087301\n",
      "model:7, iteration:200, loss:0.417536876411\n",
      "model:7, iteration:300, loss:0.414901277269\n",
      "model:7, iteration:400, loss:0.412805331538\n",
      "model:7, iteration:500, loss:0.412054343257\n",
      "model:7, iteration:600, loss:0.411334021309\n",
      "model:7, iteration:700, loss:0.411120514986\n",
      "model:7, iteration:800, loss:0.410860219894\n",
      "model:7, iteration:900, loss:0.410643297329\n",
      "model:7, iteration:1000, loss:0.410468745584\n",
      "model:8, iteration:100, loss:0.435836955946\n",
      "model:8, iteration:200, loss:0.411380648888\n",
      "model:8, iteration:300, loss:0.40879718465\n",
      "model:8, iteration:400, loss:0.407589378692\n",
      "model:8, iteration:500, loss:0.407045434251\n",
      "model:8, iteration:600, loss:0.4067487076\n",
      "model:8, iteration:700, loss:0.406706979661\n",
      "model:8, iteration:800, loss:0.406450816611\n",
      "model:8, iteration:900, loss:0.406418884073\n",
      "model:8, iteration:1000, loss:0.406251438625\n",
      "model:9, iteration:100, loss:0.434608382327\n",
      "model:9, iteration:200, loss:0.411606238877\n",
      "model:9, iteration:300, loss:0.410406806533\n",
      "model:9, iteration:400, loss:0.410457797402\n",
      "model:10, iteration:100, loss:0.426291096701\n",
      "model:10, iteration:200, loss:0.422775960414\n",
      "model:10, iteration:300, loss:0.422556749786\n",
      "model:10, iteration:400, loss:0.42185719908\n",
      "model:10, iteration:500, loss:0.421445403801\n",
      "model:10, iteration:600, loss:0.421440510037\n",
      "model:10, iteration:700, loss:0.421529592807\n",
      "model:11, iteration:100, loss:0.453368575625\n",
      "model:11, iteration:200, loss:0.438101550873\n",
      "model:11, iteration:300, loss:0.436711520869\n",
      "model:11, iteration:400, loss:0.435651548778\n",
      "model:11, iteration:500, loss:0.434748629755\n",
      "model:11, iteration:600, loss:0.434253327617\n",
      "model:11, iteration:700, loss:0.433782380949\n",
      "model:11, iteration:800, loss:0.433643685619\n",
      "model:11, iteration:900, loss:0.433581203731\n",
      "model:11, iteration:1000, loss:0.43344568141\n",
      "model:12, iteration:100, loss:0.440816932811\n",
      "model:12, iteration:200, loss:0.432367104424\n",
      "model:12, iteration:300, loss:0.433091099554\n",
      "model:13, iteration:100, loss:0.455546132733\n",
      "model:13, iteration:200, loss:0.426975707745\n",
      "model:13, iteration:300, loss:0.424130195388\n",
      "model:13, iteration:400, loss:0.423159184535\n",
      "model:13, iteration:500, loss:0.422953526618\n",
      "model:13, iteration:600, loss:0.422530284093\n",
      "model:13, iteration:700, loss:0.42244955\n",
      "model:13, iteration:800, loss:0.42210858082\n",
      "model:13, iteration:900, loss:0.421992559718\n",
      "model:13, iteration:1000, loss:0.4220794158\n",
      "model:14, iteration:100, loss:0.441429804108\n",
      "model:14, iteration:200, loss:0.410415268591\n",
      "model:14, iteration:300, loss:0.407788963716\n",
      "model:14, iteration:400, loss:0.40678940545\n",
      "model:14, iteration:500, loss:0.4061301767\n",
      "model:14, iteration:600, loss:0.405897968004\n",
      "model:14, iteration:700, loss:0.405834319209\n",
      "model:14, iteration:800, loss:0.405847113981\n",
      "model:15, iteration:100, loss:0.445829249422\n",
      "model:15, iteration:200, loss:0.412046844469\n",
      "model:15, iteration:300, loss:0.408240147909\n",
      "model:15, iteration:400, loss:0.406433769048\n",
      "model:15, iteration:500, loss:0.405371689948\n",
      "model:15, iteration:600, loss:0.404795648658\n",
      "model:15, iteration:700, loss:0.404541218836\n",
      "model:15, iteration:800, loss:0.404303965636\n",
      "model:15, iteration:900, loss:0.404153654227\n",
      "model:15, iteration:1000, loss:0.403966711434\n"
     ]
    }
   ],
   "source": [
    "model_para = param.copy()\n",
    "model_para['subsample'] = 0.133448450345\n",
    "model_para['colsample_bytree'] = 0.367127373623\n",
    "model_para['gamma'] = 5.18910389561\n",
    "obj,link = objective_fun[1]\n",
    "tot_loss = 0\n",
    "\n",
    "for i in range(16):\n",
    "    dtrain = xgb.DMatrix(\n",
    "        X_train, label=Y_train[:, i],\n",
    "        weight=np.tile(Weight,16)\n",
    "    )\n",
    "    dval = xgb.DMatrix(\n",
    "        X_val, label=Y_val[:, i],\n",
    "        weight=Weight)\n",
    "\n",
    "    best_loss = 100\n",
    "    best_step = 0\n",
    "    for j in range(monitorTimes):           \n",
    "        # train\n",
    "        if j == 0:\n",
    "            model = xgb.train(model_para, dtrain, monitor,obj=obj)\n",
    "        else:\n",
    "            model = xgb.train(model_para, dtrain, monitor,obj=obj,xgb_model=model)\n",
    "        # eval\n",
    "        yhat = link(model.predict(dval,output_margin=True))\n",
    "        loss = loss_func(Weight,yhat,Y_val[:, i])\n",
    "        print \"model:{}, iteration:{}, loss:{}\".format(i,(j+1)*monitor,loss)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_step = (j+1)*monitor\n",
    "            Y_ensemble[:,i] = yhat\n",
    "        else:\n",
    "            break # early stop\n",
    "    best_numberStep_list.append(best_step)\n",
    "    tot_loss = tot_loss + best_loss\n",
    "\n",
    "tot_loss = tot_loss/16    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000,\n",
       " 900,\n",
       " 500,\n",
       " 200,\n",
       " 200,\n",
       " 500,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 300,\n",
       " 600,\n",
       " 1000,\n",
       " 200,\n",
       " 900,\n",
       " 700,\n",
       " 1000]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_numberStep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_numberStep_list2 = []\n",
    "Y_ensemble2 = np.zeros((yhat.shape[0],16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:0, iteration:100, loss:0.458784031928\n",
      "model:0, iteration:200, loss:0.412901957087\n",
      "model:0, iteration:300, loss:0.405807078045\n",
      "model:0, iteration:400, loss:0.404271653414\n",
      "model:0, iteration:500, loss:0.403304264521\n",
      "model:0, iteration:600, loss:0.403040903899\n",
      "model:0, iteration:700, loss:0.40274452091\n",
      "model:0, iteration:800, loss:0.402561174964\n",
      "model:0, iteration:900, loss:0.402463396366\n",
      "model:0, iteration:1000, loss:0.402198341158\n",
      "model:1, iteration:100, loss:0.502047664898\n",
      "model:1, iteration:200, loss:0.446990787329\n",
      "model:1, iteration:300, loss:0.440590382684\n",
      "model:1, iteration:400, loss:0.43784292808\n",
      "model:1, iteration:500, loss:0.436700371386\n",
      "model:1, iteration:600, loss:0.436034819886\n",
      "model:1, iteration:700, loss:0.436550931503\n",
      "model:2, iteration:100, loss:0.484989600709\n",
      "model:2, iteration:200, loss:0.429002728707\n",
      "model:2, iteration:300, loss:0.422527021203\n",
      "model:2, iteration:400, loss:0.421637045292\n",
      "model:2, iteration:500, loss:0.421140377911\n",
      "model:2, iteration:600, loss:0.421075971644\n",
      "model:2, iteration:700, loss:0.420997994876\n",
      "model:2, iteration:800, loss:0.420888118431\n",
      "model:2, iteration:900, loss:0.420672619122\n",
      "model:2, iteration:1000, loss:0.420560308036\n",
      "model:3, iteration:100, loss:0.446011757541\n",
      "model:3, iteration:200, loss:0.424944328667\n",
      "model:3, iteration:300, loss:0.424267475549\n",
      "model:3, iteration:400, loss:0.423185486652\n",
      "model:3, iteration:500, loss:0.422590766314\n",
      "model:3, iteration:600, loss:0.422263442738\n",
      "model:3, iteration:700, loss:0.422474426679\n",
      "model:4, iteration:100, loss:0.451974820104\n",
      "model:4, iteration:200, loss:0.435695713588\n",
      "model:4, iteration:300, loss:0.437058537666\n",
      "model:5, iteration:100, loss:0.471736787996\n",
      "model:5, iteration:200, loss:0.429333834898\n",
      "model:5, iteration:300, loss:0.42488416943\n",
      "model:5, iteration:400, loss:0.423273686542\n",
      "model:5, iteration:500, loss:0.422968660411\n",
      "model:5, iteration:600, loss:0.422593017259\n",
      "model:5, iteration:700, loss:0.422100161847\n",
      "model:5, iteration:800, loss:0.421969908345\n",
      "model:5, iteration:900, loss:0.421654313244\n",
      "model:5, iteration:1000, loss:0.421505558123\n",
      "model:6, iteration:100, loss:0.496196164825\n",
      "model:6, iteration:200, loss:0.440593907305\n",
      "model:6, iteration:300, loss:0.432781253164\n",
      "model:6, iteration:400, loss:0.430827007088\n",
      "model:6, iteration:500, loss:0.429976270541\n",
      "model:6, iteration:600, loss:0.429413648257\n",
      "model:6, iteration:700, loss:0.42900424898\n",
      "model:6, iteration:800, loss:0.428661337644\n",
      "model:6, iteration:900, loss:0.428339624745\n",
      "model:6, iteration:1000, loss:0.428263634597\n",
      "model:7, iteration:100, loss:0.450225939801\n",
      "model:7, iteration:200, loss:0.417804526243\n",
      "model:7, iteration:300, loss:0.414200078121\n",
      "model:7, iteration:400, loss:0.41312815458\n",
      "model:7, iteration:500, loss:0.412826059924\n",
      "model:7, iteration:600, loss:0.412007546582\n",
      "model:7, iteration:700, loss:0.411729666627\n",
      "model:7, iteration:800, loss:0.411527558759\n",
      "model:7, iteration:900, loss:0.411283649382\n",
      "model:7, iteration:1000, loss:0.410918017473\n",
      "model:8, iteration:100, loss:0.433735426437\n",
      "model:8, iteration:200, loss:0.412394722655\n",
      "model:8, iteration:300, loss:0.409223771445\n",
      "model:8, iteration:400, loss:0.407974123722\n",
      "model:8, iteration:500, loss:0.407353429276\n",
      "model:8, iteration:600, loss:0.407039707002\n",
      "model:8, iteration:700, loss:0.406742772036\n",
      "model:8, iteration:800, loss:0.406387208316\n",
      "model:8, iteration:900, loss:0.406064064223\n",
      "model:8, iteration:1000, loss:0.405890269365\n",
      "model:9, iteration:100, loss:0.436720243799\n",
      "model:9, iteration:200, loss:0.41324414518\n",
      "model:9, iteration:300, loss:0.411510293646\n",
      "model:9, iteration:400, loss:0.410614473281\n",
      "model:9, iteration:500, loss:0.410123390223\n",
      "model:9, iteration:600, loss:0.409833500624\n",
      "model:9, iteration:700, loss:0.409527244369\n",
      "model:9, iteration:800, loss:0.409381757541\n",
      "model:9, iteration:900, loss:0.409323563378\n",
      "model:9, iteration:1000, loss:0.409294882086\n",
      "model:10, iteration:100, loss:0.433694899531\n",
      "model:10, iteration:200, loss:0.42302092029\n",
      "model:10, iteration:300, loss:0.422889307769\n",
      "model:10, iteration:400, loss:0.421202991474\n",
      "model:10, iteration:500, loss:0.420863995818\n",
      "model:10, iteration:600, loss:0.420916155514\n",
      "model:11, iteration:100, loss:0.455276983704\n",
      "model:11, iteration:200, loss:0.435357389055\n",
      "model:11, iteration:300, loss:0.434776916754\n",
      "model:11, iteration:400, loss:0.43412663561\n",
      "model:11, iteration:500, loss:0.433312613555\n",
      "model:11, iteration:600, loss:0.433010644952\n",
      "model:11, iteration:700, loss:0.432800960854\n",
      "model:11, iteration:800, loss:0.432794195674\n",
      "model:11, iteration:900, loss:0.432320219415\n",
      "model:11, iteration:1000, loss:0.432303967748\n",
      "model:12, iteration:100, loss:0.451731920549\n",
      "model:12, iteration:200, loss:0.433446921018\n",
      "model:12, iteration:300, loss:0.431721315904\n",
      "model:12, iteration:400, loss:0.430991555787\n",
      "model:12, iteration:500, loss:0.430359058124\n",
      "model:12, iteration:600, loss:0.429989288371\n",
      "model:12, iteration:700, loss:0.429613446112\n",
      "model:12, iteration:800, loss:0.429247910844\n",
      "model:12, iteration:900, loss:0.429071802405\n",
      "model:12, iteration:1000, loss:0.428608463847\n",
      "model:13, iteration:100, loss:0.456177782928\n",
      "model:13, iteration:200, loss:0.426504248932\n",
      "model:13, iteration:300, loss:0.424181241751\n",
      "model:13, iteration:400, loss:0.423181677721\n",
      "model:13, iteration:500, loss:0.422888319372\n",
      "model:13, iteration:600, loss:0.422696991018\n",
      "model:13, iteration:700, loss:0.422486625932\n",
      "model:13, iteration:800, loss:0.42254821943\n",
      "model:14, iteration:100, loss:0.441461683072\n",
      "model:14, iteration:200, loss:0.410066841862\n",
      "model:14, iteration:300, loss:0.406581870007\n",
      "model:14, iteration:400, loss:0.405589060528\n",
      "model:14, iteration:500, loss:0.405166961422\n",
      "model:14, iteration:600, loss:0.405069208493\n",
      "model:14, iteration:700, loss:0.405122782031\n",
      "model:15, iteration:100, loss:0.457718406139\n",
      "model:15, iteration:200, loss:0.418325529985\n",
      "model:15, iteration:300, loss:0.411307068425\n",
      "model:15, iteration:400, loss:0.408331734256\n",
      "model:15, iteration:500, loss:0.406841709923\n",
      "model:15, iteration:600, loss:0.406003428147\n",
      "model:15, iteration:700, loss:0.405439427758\n",
      "model:15, iteration:800, loss:0.405131848242\n",
      "model:15, iteration:900, loss:0.404747478543\n",
      "model:15, iteration:1000, loss:0.404572533421\n"
     ]
    }
   ],
   "source": [
    "model_para2 = param.copy()\n",
    "model_para2['subsample'] = 0.119398299563\n",
    "model_para2['colsample_bytree'] = 0.367823795823\n",
    "model_para2['gamma'] = 4.43745570732\n",
    "obj,link = objective_fun[1]\n",
    "tot_loss = 0\n",
    "\n",
    "for i in range(16):\n",
    "    dtrain = xgb.DMatrix(\n",
    "        X_train, label=Y_train[:, i],\n",
    "        weight=np.tile(Weight,16)\n",
    "    )\n",
    "    dval = xgb.DMatrix(\n",
    "        X_val, label=Y_val[:, i],\n",
    "        weight=Weight)\n",
    "\n",
    "    best_loss = 100\n",
    "    best_step = 0\n",
    "    for j in range(monitorTimes):           \n",
    "        # train\n",
    "        if j == 0:\n",
    "            model = xgb.train(model_para2, dtrain, monitor,obj=obj)\n",
    "        else:\n",
    "            model = xgb.train(model_para2, dtrain, monitor,obj=NWRMSLE_relu,xgb_model=model)\n",
    "        # eval\n",
    "        yhat = link(model.predict(dval,output_margin=True))\n",
    "        loss = loss_func(Weight,yhat,Y_val[:, i])\n",
    "        print \"model:{}, iteration:{}, loss:{}\".format(i,(j+1)*monitor,loss)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_step = (j+1)*monitor\n",
    "            Y_ensemble2[:,i] = yhat\n",
    "        else:\n",
    "            break # early stop\n",
    "    best_numberStep_list2.append(best_step)\n",
    "    tot_loss = tot_loss + best_loss\n",
    "\n",
    "tot_loss = tot_loss/16    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000,\n",
       " 600,\n",
       " 1000,\n",
       " 600,\n",
       " 200,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 1000,\n",
       " 500,\n",
       " 1000,\n",
       " 1000,\n",
       " 700,\n",
       " 600,\n",
       " 1000]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_numberStep_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41915811139422277"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1:0.401864974725, model2:0.402198341154, combined:0.401819730031\n",
      "model1:0.43490470465, model2:0.43603481987, combined:0.435245132073\n",
      "model1:0.421205497832, model2:0.420560307968, combined:0.420559738947\n",
      "model1:0.417062048735, model2:0.422263442743, combined:0.418423464793\n",
      "model1:0.434229300959, model2:0.435695713566, combined:0.434696929222\n",
      "model1:0.420161125373, model2:0.421505558291, combined:0.420570734608\n",
      "model1:0.428430376285, model2:0.428263634707, combined:0.428058013732\n",
      "model1:0.410468745436, model2:0.410918017332, combined:0.410457298723\n",
      "model1:0.406251438767, model2:0.40589026925, combined:0.405850052854\n",
      "model1:0.410406806262, model2:0.40929488191, combined:0.409215754369\n",
      "model1:0.421440510143, model2:0.420863995878, combined:0.420969839292\n",
      "model1:0.433445681606, model2:0.432303967905, combined:0.432621998666\n",
      "model1:0.432367104447, model2:0.428608464103, combined:0.42912545019\n",
      "model1:0.421992559822, model2:0.422486625891, combined:0.422049304686\n",
      "model1:0.405834319093, model2:0.405069208475, combined:0.405226808768\n",
      "model1:0.403966711402, model2:0.404572533555, combined:0.404025889731\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    print \"model1:{}, model2:{}, combined:{}\"\\\n",
    "    .format(loss_func(Weight,Y_ensemble[:,i],Y_val[:, i]),\\\n",
    "            loss_func(Weight,Y_ensemble2[:,i],Y_val[:, i]),\\\n",
    "            loss_func(Weight,(Y_ensemble[:,i]+Y_ensemble2[:,i])/2,Y_val[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
