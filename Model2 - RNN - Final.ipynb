{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from functions import RNN_generator,createGraphRNN,init_state_update,RNN_forecast\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discreteList = ['dayOfWeek','payDay','month','earthquake','type','locale','locale_name','transferred','onpromotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "seq_len = 16 # same as test set for convenience\n",
    "learningRate = 1e-4\n",
    "epoch = 30\n",
    "keep_prob = 0.75\n",
    "n_layers = 2\n",
    "grad_clip = 5.0\n",
    "bucketSize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinalitys_X = [55, 4001, 34, 337, 2, 23, 17, 6, 18]\n",
    "cardinalitys_T = [7, 2, 13, 2, 7, 4, 25, 2, 3]\n",
    "dimentions_X = [2, 20, 1, 2, 1, 1, 1, 1, 1]\n",
    "dimentions_T = [1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dX = sum(dimentions_X)\n",
    "dT = sum(dimentions_T)\n",
    "d = dX + dT + 2 # 2 for two cont variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Build Computation Graph ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs,train_op,cost,saver,yhat,state = createGraphRNN(batch_size,seq_len,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monitor = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'train_final'\n",
    "y_np = np.loadtxt(prefix+'_Y',dtype=np.float32, delimiter=\",\") \n",
    "weight_np = np.loadtxt(prefix+'_Weight',dtype=np.float32, delimiter=\",\") \n",
    "Con_np = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Count_np = np.loadtxt(prefix+'_Count',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:0.636511577953\n",
      "Train loss:0.968842682815\n",
      "Train loss:1.04433992075\n",
      "Train loss:0.82437184032\n",
      "Train loss:0.900429566988\n",
      "Train loss:1.08760504307\n",
      "Train loss:0.814018178747\n",
      "Train loss:0.645312193267\n",
      "Train loss:0.813628841162\n",
      "Train loss:0.675931445994\n",
      "Train loss:0.541603960145\n",
      "Train loss:0.828752815207\n",
      "Train loss:0.596420544171\n",
      "Train loss:0.833746130898\n",
      "Train loss:0.95236270647\n",
      "Train loss:0.569947677707\n",
      "Train loss:0.624942583593\n",
      "Train loss:0.666621331775\n",
      "Train loss:0.964010395789\n",
      "Train loss:0.792642703402\n",
      "Train loss:0.633126946624\n",
      "Train loss:0.698547485528\n",
      "Train loss:0.638245940162\n",
      "Train loss:0.959674824896\n",
      "Train loss:0.622096158467\n",
      "Train loss:0.653523635809\n",
      "Train loss:0.606417494125\n",
      "Train loss:0.530936422685\n",
      "Train loss:0.941848247789\n",
      "Train loss:0.687379700177\n"
     ]
    }
   ],
   "source": [
    "init_state = tuple([np.zeros((batch_size,d),dtype=np.float32) for i in range(n_layers)])\n",
    "for i in range(epoch):\n",
    "    cost_train = .0\n",
    "    weight_train = .0\n",
    "    #cost_val = .0\n",
    "    #weight_val = .0\n",
    "    for j,X_nps in enumerate(RNN_generator(y_np, weight_np,Con_np,Dis_np,X_np,Count_np,\\\n",
    "                              batch_size,seq_len,bucketSize,downSample=0.9)):\n",
    "        _,cost_np,init_state = sess.run([train_op,cost,state],\\\n",
    "                             dict(zip(inputs,X_nps+[learningRate,init_state])))\n",
    "        cost_train += cost_np\n",
    "        weight_train = weight_train + np.sum(X_nps[1])\n",
    "        \n",
    "        if j%monitor == 0:\n",
    "        \n",
    "            print \"Train loss:{}\".format(np.sqrt(seq_len*batch_size*cost_train/weight_train))\n",
    "            cost_train = .0\n",
    "            weight_train = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RNN_fillin_01'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model parameters\n",
    "saver.save(sess,'RNN_fillin_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*** Prediction ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs,train_op,cost,saver,yhat,state = createGraphRNN(None,1,cardinalitys_X,cardinalitys_T,\\\n",
    "                                                    dimentions_X,dimentions_T,\\\n",
    "                                                    dX,d,keep_prob,n_layers,grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from RNN_fillin_01\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess,'RNN_fillin_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.loadtxt('Index_final',dtype=np.int32,delimiter=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_tot_list = init_state_update(sess,inputs,state,batch_size*10,d,n_layers,\\\n",
    "                                  y_np[index],Con_np[index],X_np[index],Count_np[index],\\\n",
    "                                  [dis[index] for dis in Dis_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'test_SI_final'\n",
    "y_np_SI = np.loadtxt(prefix+'_Y',dtype=np.int32, delimiter=\",\") \n",
    "Con_np_SI = np.loadtxt(prefix+'_Con',dtype=np.float32, delimiter=\",\") \n",
    "X_np_SI = np.loadtxt(prefix+'_X',dtype=np.int32,delimiter=\",\") \n",
    "Dis_np_SI = [np.loadtxt(prefix+'_Dis'+str(j),dtype=np.int32,delimiter=\",\")  for j in range(len(discreteList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat = 10\n",
    "y_SI = np.zeros_like(y_np_SI)\n",
    "for i in range(repeat):\n",
    "    y_SI = y_SI + RNN_forecast(sess,inputs,state,yhat,batch_size*10,n_layers,\\\n",
    "                             np.expand_dims(y_np[index,Count_np[index]-1],-1)\\\n",
    "                            ,Con_np_SI,X_np_SI,Dis_np_SI,init_tot_list)\n",
    "y_SI = y_SI/repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'id':y_np_SI.flatten(),'unit_sales':y_SI.flatten()}).to_csv('RNN_01.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
