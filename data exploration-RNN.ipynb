{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: downweight zero sales and use frequency on test store-item pair to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isConsecutive(seq):\n",
    "    # if non-consecutive, need to re-map to consecutive number starting from 1\n",
    "    uniq = pd.unique(seq)\n",
    "    return len(uniq) == (uniq.max()-uniq.min() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isUniqBigger(seq1,seq2):\n",
    "    return set(seq1) >= set(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reMapDF(df,cols):\n",
    "    # remap cols in dataframe to consecutive integers starting from one\n",
    "    for col in cols:\n",
    "        uniq = pd.unique(df[col])\n",
    "        dict_ = {item:i+1 for i,item in enumerate(uniq)}\n",
    "        df = df.replace({col:dict_})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dimentionDF(df,cols):\n",
    "    return {col:len(set(df[col])) for col in cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeFillCast(df1,df2,key):\n",
    "    cols = df2.columns.values\n",
    "    types = df2.dtypes.values\n",
    "    dict_ = {col:type_ for col,type_ in zip(cols,types)}\n",
    "    dfOut = pd.merge(df1, df2, how='left', on=key, \n",
    "             suffixes=('', '_y'), copy=True, indicator=False).fillna(0)\n",
    "    dfOut[cols] = \\\n",
    "        dfOut[cols].astype(dict_)\n",
    "    return dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeFillCastsss(df0,dfs,keys):\n",
    "    for df,key in zip(dfs,keys):\n",
    "        df0 = mergeFillCast(df0,df,key)\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = {'id': 'int32',\n",
    "         'item_nbr': 'int32',\n",
    "         'store_nbr': 'int8',\n",
    "         'unit_sales': 'float32',\n",
    "         'onpromotion': bool}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/will/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',usecols=['date','item_nbr','store_nbr','unit_sales','onpromotion'],\\\n",
    "                    parse_dates=['date'],dtype=types, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(2,axis=1)\n",
    "train.onpromotion = train.onpromotion.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales  onpromotion\n",
       "0 2013-01-01         25    103665         7.0            2\n",
       "1 2013-01-01         25    105574         1.0            2\n",
       "2 2013-01-01         25    105575         2.0            2\n",
       "3 2013-01-01         25    108079         1.0            2\n",
       "4 2013-01-01         25    108701         1.0            2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv',parse_dates=['date'],dtype=types, infer_datetime_format=True)\n",
    "test = test.fillna(2,axis=1)\n",
    "test.onpromotion = test.onpromotion.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needs to map items2 before mapping item_nbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv('items.csv')\n",
    "stores = pd.read_csv('stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items2 = reMapDF(items,['family','class'])\n",
    "items2[['family','class','perishable']] = \\\n",
    "        items2[['family','class','perishable']].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores2 = reMapDF(stores,['city', 'state', 'type'])\n",
    "stores2 = stores2.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = train[train.date >= '2017-07-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train.date < '2017-07-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_uniq = pd.unique(train.item_nbr)\n",
    "item_dict = {item:i+1 for i,item in enumerate(item_uniq)}\n",
    "iter_mapping = lambda x: item_dict[x] if x in item_dict else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create date related variables. Multiple holiday can be on the same date. Sample one holiday from many to create multiple holiday lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays_events = pd.read_csv('holidays_events.csv',parse_dates=['date'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays_events_list = [holidays_events.groupby('date').apply(lambda x: x.sample(frac=1)).reset_index(drop=True)\\\n",
    "                                .groupby('date').first().reset_index() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays_events_list2 = [reMapDF(holiday.drop('description',1),['type', 'locale', 'locale_name'])\\\n",
    "                        for holiday in holidays_events_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "for holiday in holidays_events_list2:\n",
    "    holiday[['type', 'locale', 'locale_name','transferred']] = \\\n",
    "        holiday[['type', 'locale', 'locale_name','transferred']].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar = pd.DataFrame(pd.date_range('2013-01-01', '2017-08-31'),columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar['dayOfWeek'] = dateVar.date.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar['payDay'] = ((dateVar.date.dt.day == dateVar.date.dt.days_in_month) | \\\n",
    "                     (dateVar.date.dt.day == 15)) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar['month'] = dateVar.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar['earthquake'] = (dateVar.date > '2016-04-16') & (dateVar.date <= '2016-04-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['date', 'dayOfWeek', 'payDay', 'month', 'earthquake'], dtype=object)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateVar.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar[['dayOfWeek', 'payDay', 'month', 'earthquake']] = \\\n",
    "    dateVar[['dayOfWeek', 'payDay', 'month', 'earthquake']].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oil = pd.read_csv('oil.csv',parse_dates=['date'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dateVar = pd.merge(dateVar,oil,'left','date').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dateVar_list = [pd.merge(dateVar,holiday,'left','date').fillna(0)\\\n",
    "               for holiday in holidays_events_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>payDay</th>\n",
       "      <th>month</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  dayOfWeek  payDay  month  earthquake  dcoilwtico  type  locale  \\\n",
       "0 2013-01-01          1       0      1           0       93.14   1.0     3.0   \n",
       "1 2013-01-02          2       0      1           0       93.14   0.0     0.0   \n",
       "2 2013-01-03          3       0      1           0       92.97   0.0     0.0   \n",
       "3 2013-01-04          4       0      1           0       93.12   0.0     0.0   \n",
       "4 2013-01-05          5       0      1           0       93.20   5.0     3.0   \n",
       "\n",
       "   locale_name  transferred  \n",
       "0         12.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          0.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4         12.0          0.0  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateVar_list[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"dateVar.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(dateVar_list, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(r\"dateVar.pickle\", \"rb\") as input_file:\n",
    "    dateVar_list = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first date that store has sales on any items as the first date to densify the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateData(data):\n",
    "    SI_timeMinMax = data.groupby(['store_nbr','item_nbr'])['date'].agg([np.count_nonzero]).reset_index()\n",
    "    SI_train_sales = data.groupby(['store_nbr','item_nbr'])[['date','unit_sales']].\\\n",
    "                    agg(lambda x: tuple(x)).reset_index()\n",
    "    storeTime = data.groupby(['store_nbr'])['date'].agg([np.min,np.max]).reset_index()\n",
    "    dfs = [items2,stores2,SI_train_sales,storeTime]\n",
    "    keys = ['item_nbr','store_nbr',['item_nbr','store_nbr'],'store_nbr']\n",
    "    SI_train = mergeFillCastsss(SI_timeMinMax,dfs,keys)\n",
    "    SI_train['item_nbr'] = SI_train.item_nbr.map(iter_mapping)\n",
    "    SI_train['sampleWeight'] = SI_train.count_nonzero/((SI_train.amax - SI_train.amin).dt.days)\n",
    "    SI_train.drop('count_nonzero',1,inplace=True)\n",
    "    return SI_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRNN = CreateData(train)\n",
    "valRNN = CreateData(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRNN['amin']=pd.to_datetime(trainRNN['amin'])\n",
    "trainRNN['amax']=pd.to_datetime(trainRNN['amax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "valRNN['amin']=pd.to_datetime(valRNN['amin'])\n",
    "valRNN['amax']=pd.to_datetime(valRNN['amax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRNN.to_csv('trainRNN.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valRNN.to_csv('valRNN.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRNN = pd.read_csv('trainRNN.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valRNN = pd.read_csv('valRNN.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN_generator(data,batchSize,seqSize,df,key,discreteList,shuffle=True,downSample=1):\n",
    "    # return bool (if init should be reset) \n",
    "    # and a list [y (B,T),weight (B,T),Xcontinue of shape (B,T,2)] + [Xdiscrete] of shape (B,T) + [X] of shape (B,)\n",
    "    # finetune by use store-item pair in testset only\n",
    "    if shuffle:\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "    n = data.shape[0]\n",
    "\n",
    "    for from_ in range(0,n-batchSize,batchSize):\n",
    "        X = list(data.loc[from_:from_+batchSize-1,'store_nbr':'cluster'].values.astype(np.int32).T)\n",
    "        weight = np.ones((batchSize,1),dtype=np.float32)\n",
    "        weight[data.loc[from_:from_+batchSize-1,'perishable']==1] = 1.25\n",
    "        for j,(y,w,Xdiscrete,Xcontinue) in enumerate(timeGenerator(\\\n",
    "                           data.loc[from_:from_+batchSize-1,'date':'amax'],seqSize,downSample,df,key,discreteList)):\n",
    "            yield j==0, [y,weight*w,Xcontinue] + Xdiscrete + X\n",
    "            \n",
    "def timeGenerator(data,seqSize,downSample,df,key,discreteList):\n",
    "    # df is time related variables like holiday and seasonality\n",
    "    # returns y, weight, X_discrete, X_continue\n",
    "    n = data.shape[0]\n",
    "    data['curr'] = data.amin \n",
    "    sparse = pd.concat([data.apply(lambda x: pd.Series(x.date,name='date'),axis=1)\\\n",
    "                                    .stack().reset_index().drop(['level_1'],1),\\\n",
    "                        data.apply(lambda x: pd.Series(x.unit_sales),axis=1)\\\n",
    "                                    .stack().reset_index().drop(['level_0','level_1'],1)],1)\n",
    "    sparse.columns = ['level','date','sales']\n",
    "    while np.all(data.curr + pd.DateOffset(seqSize) <= data['amax']):\n",
    "        dense = data.apply(lambda x:pd.Series(pd.date_range(x.curr,periods=seqSize+1)),axis=1)\\\n",
    "                            .stack().reset_index().drop(['level_1'],1)\n",
    "        dense.columns = ['level','date']\n",
    "        dense = pd.merge(pd.merge(dense, df[np.random.randint(10)], how='left', on=key),\n",
    "                        sparse,how='left',on=['level','date']).fillna(0)\n",
    "        dense_continue = dense[['dcoilwtico','sales']].values.astype(np.float32)\\\n",
    "                                  .reshape((n,seqSize+1,2))[:,:seqSize,:]\n",
    "        dense_discrete = list(np.moveaxis(dense[discreteList].values.astype(np.int32)\\\n",
    "                                                .reshape((n,seqSize+1,len(discreteList)))[:,:seqSize,:]\\\n",
    "                                          ,2,0))\n",
    "        y = dense['sales'].values.astype(np.float32).reshape((n,seqSize+1))[:,1:]\n",
    "        weight = np.ones_like(y,dtype=np.float32)\n",
    "        weight[y==0] = downSample\n",
    "        yield y, weight, dense_discrete, dense_continue\n",
    "        data.curr = data.curr + pd.DateOffset(seqSize)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# of shape (B,T)\n",
    "discreteList = ['dayOfWeek','payDay','month','earthquake','type','locale','locale_name','transferred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# of shape (B,)\n",
    "Xlist = ['store_nbr','item_nbr',\n",
    " 'family', 'class',\n",
    " 'perishable', 'city',\n",
    " 'state', 'type', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = RNN_generator(trainRNN,5,3,dateVar_list,'date',discreteList,shuffle=True,downSample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = g.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80000001,  0.80000001,  0.80000001],\n",
       "       [ 0.80000001,  0.80000001,  0.80000001],\n",
       "       [ 1.        ,  1.        ,  1.        ],\n",
       "       [ 0.80000001,  0.80000001,  0.80000001],\n",
       "       [ 0.80000001,  0.80000001,  0.80000001]], dtype=float32)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93.12000275,  93.19999695,  93.19999695],\n",
       "       [ 38.22000122,  39.15000153,  38.5       ],\n",
       "       [ 93.19999695,  93.19999695,  93.19999695],\n",
       "       [ 93.19999695,  93.19999695,  93.19999695],\n",
       "       [ 93.19999695,  93.19999695,  93.19999695]], dtype=float32)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2][:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6],\n",
       "       [0, 1, 2],\n",
       "       [5, 6, 0],\n",
       "       [5, 6, 0],\n",
       "       [5, 6, 0]], dtype=int32)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([25, 42, 38, 54, 38], dtype=int32),\n",
       " array([3834, 1694, 1732, 1170,  947], dtype=int32),\n",
       " array([9, 1, 6, 1, 1], dtype=int32),\n",
       " array([333,  26,  18,  22,   7], dtype=int32),\n",
       " array([0, 0, 1, 0, 0], dtype=int32),\n",
       " array([11, 17, 18, 22, 18], dtype=int32),\n",
       " array([10, 12, 13, 16, 13], dtype=int32),\n",
       " array([1, 1, 1, 3, 1], dtype=int32),\n",
       " array([1, 2, 4, 3, 4], dtype=int32)]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
